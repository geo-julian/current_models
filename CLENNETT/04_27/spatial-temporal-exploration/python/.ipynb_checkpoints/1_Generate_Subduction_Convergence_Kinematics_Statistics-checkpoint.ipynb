{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Generate Subduction Convergence Kinematics Statistics \n",
    "\n",
    "In this notebook, we are going to show you how to generate subduction convergence kinematics statistics. The data generated in this step will be used in the subsequent steps of this spatial temporal exploration workflow.\n",
    "\n",
    "The script finds subduction zones using so-called \"topological plate boundaries\" in our global plate model. We sample the subduction zones and calculate subduction convergence kinematics statistics at each trench sampling point.\n",
    "\n",
    "The implementation details can be found in [convergence.py](convergence.py) which depends on the PlateTectonicTools package. You can find the package at [https://github.com/EarthByte/PlateTectonicTools.git](https://github.com/EarthByte/PlateTectonicTools.git).\n",
    "    \n",
    "The parameters used to run convergence.py can be found in [parameters.py](parameters.py).\n",
    "\n",
    "Relevant parameters:\n",
    "* plate_tectonic_tools_path -- the path to the PlateTectonicTools code\n",
    "* rotation_files -- location of the rotation files\n",
    "* topology_files -- location of the topology files\n",
    "* threshold_sampling_distance_degrees -- the default threshold sampling distance along trenches (subduction zones)\n",
    "* time.start -- start time\n",
    "* time.end -- end time\n",
    "* time.step -- time interval between steps\n",
    "* velocity_delta_time -- time interval for velocity calculation\n",
    "* anchor_plate_id - the anchor plate id\n",
    "* convergence_data_filename_prefix -- the prefix of the output files\n",
    "* convergence_data_filename_ext -- the extension name of the output files\n",
    "* convergence_data_dir -- the name of the folder in which the output files go\n",
    "\n",
    "You may modify the above parameters, restart the notebook kernel and re-run the script to see the differences. \n",
    "\n",
    "Now, let's run the script and check out the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running convergence...\n",
      "this may take a while, be patient...\n",
      "\n",
      "{ 'anchor_plate_id': 0,\n",
      "  'convergence_data_dir': './convergence_data/',\n",
      "  'convergence_data_filename_ext': 'csv',\n",
      "  'convergence_data_filename_prefix': 'subStats',\n",
      "  'coreg_input_files': [ 'positive_deposits.csv',\n",
      "                         'negative_deposits.csv',\n",
      "                         'deposit_candidates.csv'],\n",
      "  'coreg_output_dir': 'coreg_output',\n",
      "  'grid_files': [],\n",
      "  'plate_tectonic_tools_path': '../../PlateTectonicTools/ptt/',\n",
      "  'regions': [5, 50, 100],\n",
      "  'rotation_files': ['../data/2019_v2_Clennett/*.rot'],\n",
      "  'static_polygons_file': '../data/Shapefiles/StaticPolygons/Global_EarthByte_GPlates_PresentDay_StaticPlatePolygons_2015_v1.shp',\n",
      "  'threshold_sampling_distance_degrees': 0.2,\n",
      "  'time': {'end': 230, 'start': 0, 'step': 1},\n",
      "  'topology_files': ['../data/2019_v2_Clennett/*.gpml'],\n",
      "  'vector_files': ['./convergence_data/subStats_{time:.2f}.csv'],\n",
      "  'velocity_delta_time': 1}\n",
      "230 "
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./convergence_data/subStats_230.00.csv does not exist: './convergence_data/subStats_230.00.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7bad5cbc6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#this will generate a bunch of Subduction Convergence Kinematics Statistics files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#by default the files are placed in ./convergence_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mconvergence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# now, let's list all the output files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/python/convergence.py\u001b[0m in \u001b[0;36mrun_it\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtrench_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'_{age:.2f}.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv_ext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mtrench_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrench_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;31m#print(trench_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         trench_data.to_csv(f'./convergence_data/subStats_{age}.00.csv', index=False, float_format='%.2f',\n",
      "\u001b[0;32m/opt/conda/envs/pyGEOL/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pyGEOL/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pyGEOL/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pyGEOL/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pyGEOL/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./convergence_data/subStats_230.00.csv does not exist: './convergence_data/subStats_230.00.csv'"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "import glob, os\n",
    "import convergence \n",
    "\n",
    "print('running convergence...')\n",
    "print('this may take a while, be patient...')\n",
    "print('')\n",
    "\n",
    "#run the convergence script\n",
    "#this will generate a bunch of Subduction Convergence Kinematics Statistics files\n",
    "#by default the files are placed in ./convergence_data\n",
    "convergence.run_it()\n",
    "\n",
    "# now, let's list all the output files\n",
    "files = sorted(glob.glob('./convergence_data/subStats_*.csv'), key=os.path.getmtime)\n",
    "print('The number of generated files: ', len(files))\n",
    "print('The first 10 files:')\n",
    "for i in range(10):\n",
    "    print(files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell took a while to finish and created 231 csv files. Each file contains the subduction convergence kinematics statistics at certain time. For example, the file \"subStats_230.00.csv\" contains data at time 230Ma.\n",
    "\n",
    "Now, let's open one of the files and see what is inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('./convergence_data/subStats_0.00.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3029 rows in the csv file, which means there are 3029 trench sampling points. Each row contains data for each sampled point along trench. \n",
    "\n",
    "There are 20 columns in the csv file. They are the subduction convergence kinematics statistics. The meaning of each column is listed below.\n",
    "\n",
    "* 0 longitude of sample point\n",
    "* 1 latitude of sample point\n",
    "* 2 subducting convergence (relative to trench) velocity magnitude (in cm/yr)\n",
    "* 3 subducting convergence velocity obliquity angle (angle between trench normal vector and convergence velocity vector)\n",
    "* 4 trench absolute (relative to anchor plate) velocity magnitude (in cm/yr)\n",
    "* 5 trench absolute velocity obliquity angle (angle between trench normal vector and trench absolute velocity vector)\n",
    "* 6 length of arc segment (in degrees) that current point is on\n",
    "* 7 trench normal azimuth angle (clockwise starting at North, ie, 0 to 360 degrees) at current point\n",
    "* 8 subducting plate ID\n",
    "* 9 trench plate ID\n",
    "* 10 distance (in degrees) along the trench line to the nearest trench edge\n",
    "* 11 the distance (in degrees) along the trench line from the start edge of the trench\n",
    "* 12 convergence velocity orthogonal component(in cm/yr)\n",
    "* 13 convergence velocity parallel component(in cm/yr) \n",
    "* 14 the trench plate absolute velocity orthogonal component(in cm/yr)\n",
    "* 15 the trench plate absolute velocity parallel component(in cm/yr)\n",
    "* 16 the subducting plate absolute velocity magnitude (in cm/yr)\n",
    "* 17 the subducting plate absolute velocityobliquity angle (in degrees)\n",
    "* 18 the subducting plate absolute velocity orthogonal component       \n",
    "* 19 the subducting plate absolute velocity parallel component\n",
    "\n",
    "Now, let's draw some maps to visualize the data. The data visualization is important because it allows trends and patterns to be more easily seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import requests, os, glob\n",
    "import pygplates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from parameters import parameters as params\n",
    "import Utils\n",
    "\n",
    "trench_data = Utils.get_trench_points(0)\n",
    "\n",
    "#change this number to see the trench colored by different property. \n",
    "#The meaning of this number can be found in the Markdown cell above\n",
    "color_by = 11\n",
    "\n",
    "#get topological plates boundaries\n",
    "time = 0\n",
    "resolved_topologies = []\n",
    "shared_boundary_sections = []\n",
    "\n",
    "rotation_files = Utils.get_files(params['rotation_files'])\n",
    "topology_files = Utils.get_files(params[\"topology_files\"])\n",
    "   \n",
    "#use pygplates to resolve the topologies\n",
    "pygplates.resolve_topologies(topology_files, rotation_files, resolved_topologies, time, \n",
    "                             shared_boundary_sections)\n",
    "\n",
    "geoms = [t.get_resolved_boundary() for t in resolved_topologies]           \n",
    "\n",
    "#now, plot the data in a global map    \n",
    "fig = plt.figure(figsize=(16,12),dpi=150)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "for geom in geoms:\n",
    "    lat, lon =zip(*(geom.to_lat_lon_list()))\n",
    "    plt.plot(lon, lat,\n",
    "         color='white', linewidth=.5, #the topological plates boundaries in white\n",
    "         transform=ccrs.Geodetic(),\n",
    "    )\n",
    "    \n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -60, -30, 0, 30, 60, 90, 120, 150, 180])\n",
    "gl.ylocator = mticker.FixedLocator([-90, -75, -60, -45, -30, -15, 0, 15, 30, 45, 60, 75, 90])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "gl.ylabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "\n",
    "#the subduction sample points are colored by property value. see \"color_by\" above\n",
    "cb=ax.scatter(trench_data['trench_lon'], trench_data['trench_lat'], 30, marker='.', \n",
    "              c=trench_data.iloc[:,color_by]* 6371. * np.pi / 180, cmap=plt.cm.jet)\n",
    "plt.title('Present-day Subduction Zones(coloured by \"Distance Along Trench\") and Topological Boundaries(in white)')\n",
    "fig.colorbar(cb, shrink=0.5, label='Distance Along Trench(km)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Take a closer look at South America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#get South America trench data\n",
    "data_south_america = Utils.get_trench_points(0,-85,5,-70,-60)\n",
    "\n",
    "#print(data_south_america.iloc[:,9].unique())\n",
    "\n",
    "#now, plot the data in a regional map    \n",
    "fig = plt.figure(figsize=(6,6),dpi=150)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "ax.set_extent([-85, -29, -55, 15])\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -80, -70, -60,-50,-40,-30, 0, 180])\n",
    "gl.ylocator = mticker.FixedLocator([-90,-50,-40, -30, -20,-10, 0, 10, 20, 30, 40,50, 90])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'color': 'gray', 'weight': 'bold', 'fontsize': '5'}\n",
    "gl.ylabel_style = {'color': 'gray', 'weight': 'bold', 'fontsize': '5'}\n",
    "\n",
    "#the subduction sample points are colored by property value. see \"color_by\" above\n",
    "cb=ax.scatter(data_south_america['trench_lon'], data_south_america['trench_lat'], 30, marker='.', \n",
    "              c=data_south_america.iloc[:,color_by]* 6371. * np.pi / 180, cmap=plt.cm.jet)\n",
    "plt.title('Present-day South America Subduction Zones(coloured by \"Distance Along Trench\")')\n",
    "fig.colorbar(cb, shrink=0.5, label='Distance Along Trench(km)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a reconstruction map\n",
    "This is a reconstructed map with a paleo-age grid, paleo-coastlines, plate boundaries and subduction teeth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import cartopy.crs as ccrs\n",
    "from netCDF4 import Dataset\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "\n",
    "import Utils, pygplates\n",
    "\n",
    "time = 50\n",
    "draw_velocity_vectors = True\n",
    "\n",
    "#change the extent to see specific area\n",
    "#map_extent = [-85, -30, -55, 15]\n",
    "map_extent = [-180, 180, -90, 90]\n",
    "\n",
    "agegrid_file = Utils.download_agegrid(time)\n",
    "agegrid_cmap = Utils.get_age_grid_color_map_from_cpt('agegrid.cpt')\n",
    "\n",
    "#reconstruct coastlines and topology\n",
    "print(\"reconstructing geometries...\")\n",
    "data_dir = '../data/'\n",
    "\n",
    "resolved_topologies = []\n",
    "shared_boundary_sections = []\n",
    "#use pygplates to resolve the topologies\n",
    "pygplates.resolve_topologies(topology_files, rotation_files, resolved_topologies, time, \n",
    "                             shared_boundary_sections)\n",
    "\n",
    "#coastlines\n",
    "reconstructed_geometries = []\n",
    "pygplates.reconstruct(\n",
    "                data_dir + 'Shapefiles/Coastlines/Global_coastlines_2015_v1_low_res.shp', \n",
    "                rotation_files, \n",
    "                reconstructed_geometries, \n",
    "                time, 0)\n",
    "\n",
    "#subduction zones\n",
    "subduction_geoms=[]\n",
    "Utils.get_subduction_geometries(subduction_geoms, shared_boundary_sections)\n",
    "\n",
    "#velocity vectors\n",
    "x,y, u,v = Utils.get_velocity_x_y_u_v(time,pygplates.RotationModel(rotation_files),topology_files)\n",
    "       \n",
    "# plot the map\n",
    "fig = plt.figure(figsize=(16,12),dpi=150)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=0))\n",
    "ax.set_extent(map_extent)\n",
    "img = Dataset(agegrid_file) #age grid\n",
    "cb=ax.imshow(np.roll(img.variables['z'],1800), origin='lower', transform=ccrs.PlateCarree(),\n",
    "          extent=[-180, 180, -90, 90], cmap=agegrid_cmap)\n",
    "\n",
    "#plot coastlines\n",
    "for geom in reconstructed_geometries:\n",
    "    lat, lon =zip(*(geom.get_reconstructed_geometry().to_lat_lon_list()))\n",
    "    plt.plot(lon, lat,\n",
    "         color='black', linewidth=.5, #the coastlines in black\n",
    "         transform=ccrs.Geodetic(),\n",
    "    )\n",
    "\n",
    "#plot topological plates boundaries\n",
    "for t in resolved_topologies:\n",
    "    lat, lon =zip(*(t.get_resolved_boundary().to_lat_lon_list()))\n",
    "    plt.plot(lon, lat,\n",
    "         color='blue', linewidth=.5, #the topological plates boundaries in blue\n",
    "         transform=ccrs.Geodetic(),\n",
    "    )\n",
    " \n",
    "#plot subduction zones\n",
    "for geom, aspect in subduction_geoms:\n",
    "    lat, lon =zip(*(geom.to_lat_lon_list()))\n",
    "    plt.plot(lon, lat,\n",
    "         color='blue', linewidth=3, #the subduction zones in blue\n",
    "         transform=ccrs.Geodetic(),\n",
    "    )\n",
    "    teeth = Utils.get_subduction_teeth(lon, lat, triangle_aspect=aspect)\n",
    "    for tooth in teeth:\n",
    "        ring = LinearRing(tooth)\n",
    "        ax.add_geometries([ring], ccrs.PlateCarree(), facecolor='b', edgecolor='black', alpha=1)\n",
    "\n",
    " \n",
    "if draw_velocity_vectors:\n",
    "    #draw the velocity vectors\n",
    "    #Some arrows are long and some are very short. To make the plot clearer, we nomalize the velocity magnitude.\n",
    "    #And use color to denote the different speed.\n",
    "    u = np.array(u)\n",
    "    v = np.array(v)\n",
    "    mag = np.sqrt(u*u+v*v)\n",
    "    u = u/mag\n",
    "    v = v/mag\n",
    "    ax.quiver(x, y, u, v, mag,transform=ccrs.PlateCarree(),cmap='jet')    \n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlocator = mticker.FixedLocator([-180, -150, -120, -90, -60, -30, 0, 30, 60, 90, 120, 150, 180])\n",
    "gl.ylocator = mticker.FixedLocator([-90, -75, -60, -45, -30, -15, 0, 15, 30, 45, 60, 75, 90])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "gl.ylabel_style = {'color': 'gray', 'weight': 'bold'}\n",
    "\n",
    "plt.title(f'Reconstruction Map with Paleo-age Grid, Paleo-coastlines and Plate Boundaries at {time} Ma')\n",
    "fig.colorbar(cb, shrink=0.5, label='Age(Ma)')\n",
    "plt.show()   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the end of step 1 and now open the step 2 notebook --  \"2_Plot_and_Select_Mineral_Resources.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
